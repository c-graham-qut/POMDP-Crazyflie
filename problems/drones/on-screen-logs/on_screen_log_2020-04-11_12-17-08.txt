Seed: 1586600229
InitialPositions = (6, 1) (6, 4) 
Constructed the DronesModel
Discount: 1
Size: 7 by 8
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
164800 histories in 1000.01ms.
Total solving time: 1000.05ms
Saving to file...    Done.
Global seed: 1586600233

Run #1
PRNG engine state: 1037582195
InitialPositions = (6, 1) (6, 4) 
Constructed the DronesModel
Discount: 1
Size: 7 by 8
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (6, 1) (6, 4) 
Constructed the DronesModel
Discount: 1
Size: 7 by 8
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0 
Running...


t-0
State: (6, 1) (6, 4) isLanded: 0
Heuristic Value: 0
Belief #0
........
........
........
........
........
........
.1..2...
162027 histories in 1000.01ms.
Before:                                 After:                                  
-5.02073 from 164800 p. with 164800 starts.-5.01148 from 326827 p. with 326827 starts.
Action children:                        Action children:                        
   -5.00:              LAND  161859        -5.00:              LAND  323647     
   -5.91:             WIDER    1223        -5.93:             WIDER    1298     
   -6.22:           FORWARD     700        -6.24:         REARRANGE     768     
   -6.23:         REARRANGE     701        -6.25:           FORWARD     740     
   -6.86:          NARROWER     317        -6.78:          NARROWER     374     
                                                                                
Reached a terminal state!
Action: LAND
Transition: NULL
Reward: -5
Observation: (6, 1) (6, 4) isLanded = 1
Discount: 1; Total Reward: 0


Final State:
(6, 1) (6, 4) isLanded: 1
Belief #2
........
........
........
........
........
........
.1..2...
Total discounted reward: -5
# of steps: 1
Time spent on changes: 0ms
Time spent on policy updates: 1000.05ms
Time spent replenishing particles: 0.001ms
Time spent pruning: 0ms
Total time taken: 1012.61ms
Run complete!

Final State: (6, 1) (6, 4) isLanded: 1
1 runs completed.
Mean reward: -5
Mean number of steps: 1
Mean time taken to improve policy: 1000.05ms
Mean time to replenish particles: 0.001ms
Mean time taken: 1012.61ms
