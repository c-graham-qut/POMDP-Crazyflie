Seed: 1586599253
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
54902 histories in 2000.02ms.
Total solving time: 2000.04ms
Saving to file...    Done.
Global seed: 1586599259

Run #1
PRNG engine state: 198172399
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
52263 histories in 2000.03ms.
Before:                                 After:                                  
2.17677 from 54902 p. with 54902 starts.5.10055 from 107165 p. with 107165 starts.
Action children:                        Action children:                        
   +5.09:           FORWARD   38264        +6.87:           FORWARD   90527     
   -4.41:         REARRANGE    9243        -4.41:         REARRANGE    9243     
   -4.55:          NARROWER    4476        -4.55:          NARROWER    4476     
   -4.84:             WIDER    1735        -4.84:             WIDER    1735     
   -5.00:              LAND    1184        -5.00:              LAND    1184     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


t-1
State: (7, 3) (7, 9) isLanded: 0
Heuristic Value: 0
Belief #3
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
55962 histories in 2000.03ms.
Before:                                 After:                                  
7.09596 from 90527 p. with 0 starts.    7.59797 from 146489 p. with 55962 starts.
Action children:                        Action children:                        
   +7.89:           FORWARD   84615        +8.10:           FORWARD  140577     
   -4.08:         REARRANGE    2832        -4.08:         REARRANGE    2832     
   -4.20:          NARROWER    1946        -4.20:          NARROWER    1946     
   -4.64:             WIDER     718        -4.64:             WIDER     718     
   -5.00:              LAND     415        -5.00:              LAND     415     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (6, 3) (6, 9) isLanded = 0
Discount: 1; Total Reward: -0.225


t-2
State: (6, 3) (6, 9) isLanded: 0
Heuristic Value: 0
Belief #19
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 137431 of 163127 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 394.353 ms used for changes.
61045 histories in 2000.01ms.
Before:                                 After:                                  
8.32145 from 140577 p. with 0 starts.   4.84693 from 201622 p. with 61045 starts.
Action children:                        Action children:                        
   +8.52:           FORWARD  138349        +4.94:           FORWARD  199394     
   -3.62:         REARRANGE    1083        -3.62:         REARRANGE    1083     
   -3.87:          NARROWER     653        -3.87:          NARROWER     653     
   -4.33:             WIDER     330        -4.33:             WIDER     330     
   -5.00:              LAND     161        -5.00:              LAND     161     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (5, 3) (5, 9) isLanded = 0
Discount: 1; Total Reward: -0.45


t-3
State: (5, 3) (5, 9) isLanded: 0
Heuristic Value: 0
Belief #86
.............
...X.........
.............
.............
.............
...1.....2...
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 198453 of 224172 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 627.724 ms used for changes.
59992 histories in 2000.03ms.
Before:                                 After:                                  
5.16964 from 199394 p. with 0 starts.   3.41631 from 259386 p. with 59992 starts.
Action children:                        Action children:                        
   +5.20:           FORWARD  198697        +3.44:           FORWARD  258689     
   -3.17:         REARRANGE     290        -3.17:         REARRANGE     290     
   -3.44:          NARROWER     211        -3.44:          NARROWER     211     
   -3.91:             WIDER     134        -3.91:             WIDER     134     
   -5.00:              LAND      61        -5.00:              LAND      61     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (4, 3) (4, 9) isLanded = 0
Discount: 1; Total Reward: -0.675


t-4
State: (4, 3) (4, 9) isLanded: 0
Heuristic Value: 0
Belief #142
.............
...X.........
.............
.............
...1.....2...
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 258550 of 284164 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 964.449 ms used for changes.
80799 histories in 2000.03ms.
Before:                                 After:                                  
3.66008 from 258689 p. with 0 starts.   1.42015 from 339488 p. with 80799 starts.
Action children:                        Action children:                        
   +3.67:           FORWARD  258469        +1.42:           FORWARD  339254     
   -2.59:         REARRANGE      81        -2.59:         REARRANGE      81     
   -2.79:          NARROWER      68        -2.84:          NARROWER      69     
   -3.39:             WIDER      48        -3.48:             WIDER      52     
   -5.00:              LAND      22        -5.00:              LAND      31     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (3, 3) (3, 9) isLanded = 0
Discount: 1; Total Reward: -0.9


t-5
State: (3, 3) (3, 9) isLanded: 0
Heuristic Value: 0
Belief #447
.............
...X.........
...X.........
...1.....2...
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 339133 of 364963 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1201.05 ms used for changes.
98060 histories in 2000.01ms.
Before:                                 After:                                  
1.64832 from 339254 p. with 0 starts.   0.582595 from 437314 p. with 98060 starts.
Action children:                        Action children:                        
   +1.65:           FORWARD  339089        +0.59:           FORWARD  437071     
   -3.46:         REARRANGE      49        -3.42:          NARROWER      80     
   -3.50:          NARROWER      47        -3.68:         REARRANGE      70     
   -4.17:             WIDER      39        -4.42:             WIDER      51     
   -5.00:              LAND      29        -5.00:              LAND      41     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -11.225
Observation: (2, 3) (2, 9) isLanded = 0
Discount: 1; Total Reward: -1.125


t-6
State: (2, 3) (2, 9) isLanded: 0
Heuristic Value: 0
Belief #1283
.............
...X.........
...@.....2...
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 437071 of 463023 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1417.02 ms used for changes.
114185 histories in 2000.01ms.
Before:                                 After:                                  
5.30787 from 437071 p. with 0 starts.   5.89091 from 551256 p. with 114185 starts.
Action children:                        Action children:                        
   +8.11:             WIDER  159028        +8.11:             WIDER  273213     
   +3.71:           FORWARD  277969        +3.71:           FORWARD  277969     
   -2.63:         REARRANGE      32        -2.63:         REARRANGE      32     
   -4.01:          NARROWER      24        -4.01:          NARROWER      24     
   -5.00:              LAND      17        -5.00:              LAND      17     
                                                                                
Action: WIDER
Transition: NULL
Reward: -0.225
Observation: (2, 2) (2, 10) isLanded = 0
Discount: 1; Total Reward: -12.35


t-7
State: (2, 2) (2, 10) isLanded: 0
Heuristic Value: 0
Belief #6303
.............
...X.........
..1X......2..
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 273213 of 577208 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 889.604 ms used for changes.
193832 histories in 2000.01ms.
Before:                                 After:                                  
8.33962 from 273213 p. with 0 starts.   8.34343 from 467045 p. with 193832 starts.
Action children:                        Action children:                        
   +8.34:           FORWARD  273181        +8.34:           FORWARD  467012     
   -5.00:              LAND       7        -5.00:              LAND       8     
   -5.15:             WIDER       8        -5.15:             WIDER       8     
   -5.47:         REARRANGE       8        -5.47:         REARRANGE       8     
   -5.90:          NARROWER       8        -5.90:          NARROWER       8     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.825
Observation: (1, 2) (1, 10) isLanded = 0
Discount: 1; Total Reward: -12.575


t-8
State: (1, 2) (1, 10) isLanded: 0
Heuristic Value: 0
Belief #16803
.............
..1X......2..
...X.........
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 467012 of 771040 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1029.02 ms used for changes.
302481 histories in 2000.01ms.
Before:                                 After:                                  
9.16939 from 467012 p. with 0 starts.   9.17137 from 769493 p. with 302481 starts.
Action children:                        Action children:                        
   +9.17:              LAND  464756        +9.17:              LAND  767023     
   +8.15:           FORWARD    1125        +8.17:           FORWARD    1232     
   +8.13:         REARRANGE    1076        +8.15:         REARRANGE    1183     
   +4.03:             WIDER      51        +4.03:             WIDER      51     
  -15.97:          NARROWER       3       -15.97:          NARROWER       3     
                                                                                
Reached a terminal state!
Action: LAND
Transition: NULL
Reward: 9.175
Observation: (1, 2) (1, 10) isLanded = 1
Discount: 1; Total Reward: -13.4


Final State:
(1, 2) (1, 10) isLanded: 1
Belief #17013
.............
..1X......2..
...X.........
.............
.............
.............
.............
.............
.............
.............
Total discounted reward: -4.225
# of steps: 9
Time spent on changes: 6523.15ms
Time spent on policy updates: 18000.5ms
Time spent replenishing particles: 0.008ms
Time spent pruning: 0ms
Total time taken: 24594.2ms
Run complete!

Final State: (1, 2) (1, 10) isLanded: 1
1 runs completed.
Mean reward: -4.225
Mean number of steps: 9
Mean time taken to improve policy: 18000.5ms
Mean time to replenish particles: 0.008ms
Mean time taken: 24594.2ms
