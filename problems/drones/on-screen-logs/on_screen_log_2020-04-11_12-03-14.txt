Seed: 1586599394
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
54901 histories in 2000.02ms.
Total solving time: 2000.05ms
Saving to file...    Done.
Global seed: 1586599401

Run #1
PRNG engine state: 1758085673
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
51895 histories in 2000.01ms.
Before:                                 After:                                  
2.75615 from 54901 p. with 54901 starts.5.38776 from 106796 p. with 106796 starts.
Action children:                        Action children:                        
   +5.54:           FORWARD   39677        +7.03:           FORWARD   91572     
   -4.37:         REARRANGE    8336        -4.37:         REARRANGE    8336     
   -4.51:          NARROWER    4251        -4.51:          NARROWER    4251     
   -4.82:             WIDER    1583        -4.82:             WIDER    1583     
   -5.00:              LAND    1054        -5.00:              LAND    1054     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


t-1
State: (7, 3) (7, 9) isLanded: 0
Heuristic Value: 0
Belief #1
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
55871 histories in 2000.02ms.
Before:                                 After:                                  
7.25666 from 91572 p. with 0 starts.    7.6941 from 147443 p. with 55871 starts.
Action children:                        Action children:                        
   +7.96:           FORWARD   86250        +8.14:           FORWARD  142121     
   -4.03:         REARRANGE    2654        -4.03:         REARRANGE    2654     
   -4.19:          NARROWER    1629        -4.19:          NARROWER    1629     
   -4.61:             WIDER     664        -4.61:             WIDER     664     
   -5.00:              LAND     374        -5.00:              LAND     374     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (6, 3) (6, 9) isLanded = 0
Discount: 1; Total Reward: -0.225


t-2
State: (6, 3) (6, 9) isLanded: 0
Heuristic Value: 0
Belief #23
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 139412 of 162667 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 408.377 ms used for changes.
60531 histories in 2000.03ms.
Before:                                 After:                                  
8.36525 from 142121 p. with 0 starts.   4.91901 from 202652 p. with 60531 starts.
Action children:                        Action children:                        
   +8.53:           FORWARD  140241        +5.00:           FORWARD  200772     
   -3.63:         REARRANGE     824        -3.63:         REARRANGE     824     
   -3.82:          NARROWER     581        -3.82:          NARROWER     581     
   -4.20:             WIDER     331        -4.20:             WIDER     331     
   -5.00:              LAND     143        -5.00:              LAND     143     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (5, 3) (5, 9) isLanded = 0
Discount: 1; Total Reward: -0.45


t-3
State: (5, 3) (5, 9) isLanded: 0
Heuristic Value: 0
Belief #84
.............
...X.........
.............
.............
.............
...1.....2...
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 199922 of 223198 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 644.555 ms used for changes.
61151 histories in 2000.03ms.
Before:                                 After:                                  
5.22648 from 200772 p. with 0 starts.   5.61268 from 261923 p. with 61151 starts.
Action children:                        Action children:                        
   +5.25:           FORWARD  200141        +5.63:           FORWARD  261292     
   -3.13:         REARRANGE     246        -3.13:         REARRANGE     246     
   -3.33:          NARROWER     197        -3.33:          NARROWER     197     
   -3.74:             WIDER     132        -3.74:             WIDER     132     
   -5.00:              LAND      55        -5.00:              LAND      55     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (4, 3) (4, 9) isLanded = 0
Discount: 1; Total Reward: -0.675


t-4
State: (4, 3) (4, 9) isLanded: 0
Heuristic Value: 0
Belief #207
.............
...X.........
.............
.............
...1.....2...
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 261166 of 284349 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1039.34 ms used for changes.
78834 histories in 2000.02ms.
Before:                                 After:                                  
5.85963 from 261292 p. with 0 starts.   3.91435 from 340126 p. with 78834 starts.
Action children:                        Action children:                        
   +5.87:           FORWARD  261102        +3.92:           FORWARD  339936     
   -2.44:         REARRANGE      71        -2.44:         REARRANGE      71     
   -2.80:          NARROWER      56        -2.80:          NARROWER      56     
   -3.34:             WIDER      42        -3.34:             WIDER      42     
   -5.00:              LAND      20        -5.00:              LAND      20     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (3, 3) (3, 9) isLanded = 0
Discount: 1; Total Reward: -0.9


t-5
State: (3, 3) (3, 9) isLanded: 0
Heuristic Value: 0
Belief #974
.............
...X.........
...X.........
...1.....2...
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 339858 of 363183 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1214.57 ms used for changes.
100777 histories in 2000.02ms.
Before:                                 After:                                  
4.14322 from 339936 p. with 0 starts.   2.66872 from 440713 p. with 100777 starts.
Action children:                        Action children:                        
   +4.15:           FORWARD  339833        +2.67:           FORWARD  440578     
   -2.31:         REARRANGE      30        -3.11:         REARRANGE      39     
   -2.53:          NARROWER      29        -3.23:          NARROWER      38     
   -2.75:             WIDER      27        -3.44:             WIDER      35     
   -5.00:              LAND      16        -5.00:              LAND      22     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -11.225
Observation: (2, 3) (2, 9) isLanded = 0
Discount: 1; Total Reward: -1.125


t-6
State: (2, 3) (2, 9) isLanded: 0
Heuristic Value: 0
Belief #1281
.............
...X.........
...@.....2...
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 440578 of 463960 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1563.56 ms used for changes.
112299 histories in 2000.02ms.
Before:                                 After:                                  
7.37846 from 440578 p. with 0 starts.   7.69183 from 552877 p. with 112299 starts.
Action children:                        Action children:                        
   +8.91:          NARROWER  233163        +8.91:          NARROWER  345462     
   +5.66:           FORWARD  207371        +5.66:           FORWARD  207371     
   -3.24:             WIDER      16        -3.24:             WIDER      16     
   -3.28:         REARRANGE      16        -3.28:         REARRANGE      16     
   -5.00:              LAND      11        -5.00:              LAND      11     
                                                                                
Action: NARROWER
Transition: NULL
Reward: -0.225
Observation: (2, 4) (2, 8) isLanded = 0
Discount: 1; Total Reward: -12.35


t-7
State: (2, 4) (2, 8) isLanded: 0
Heuristic Value: 0
Belief #7387
.............
...X.........
...X1...2....
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 345462 of 576259 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1109.77 ms used for changes.
174728 histories in 2026.43ms.
Before:                                 After:                                  
9.13687 from 345462 p. with 0 starts.   9.14069 from 520190 p. with 174728 starts.
Action children:                        Action children:                        
   +9.14:           FORWARD  345428        +9.14:           FORWARD  520156     
   -3.95:          NARROWER       8        -3.95:          NARROWER       8     
   -3.99:         REARRANGE       9        -3.99:         REARRANGE       9     
   -5.00:              LAND       7        -5.00:              LAND       7     
   -6.21:             WIDER       9        -6.21:             WIDER       9     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.425
Observation: (1, 4) (1, 8) isLanded = 0
Discount: 1; Total Reward: -12.575


t-8
State: (1, 4) (1, 8) isLanded: 0
Heuristic Value: 0
Belief #15265
.............
...X1...2....
...X.........
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 520156 of 750987 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1186.5 ms used for changes.
314256 histories in 2000.01ms.
Before:                                 After:                                  
9.5666 from 520156 p. with 0 starts.    9.56943 from 834412 p. with 314256 starts.
Action children:                        Action children:                        
   +9.58:              LAND  513707        +9.58:              LAND  827601     
   +8.99:           FORWARD    3292        +8.99:           FORWARD    3471     
   +8.95:         REARRANGE    2884        +8.95:         REARRANGE    3053     
   +7.38:          NARROWER     269        +7.42:          NARROWER     282     
  -11.58:             WIDER       3       -11.84:             WIDER       4     
                                                                                
Reached a terminal state!
Action: LAND
Transition: NULL
Reward: 9.575
Observation: (1, 4) (1, 8) isLanded = 1
Discount: 1; Total Reward: -13


Final State:
(1, 4) (1, 8) isLanded: 1
Belief #15368
.............
...X1...2....
...X.........
.............
.............
.............
.............
.............
.............
.............
Total discounted reward: -3.425
# of steps: 9
Time spent on changes: 7166.6ms
Time spent on policy updates: 18026.9ms
Time spent replenishing particles: 0.008ms
Time spent pruning: 0ms
Total time taken: 25266.3ms
Run complete!

Final State: (1, 4) (1, 8) isLanded: 1
1 runs completed.
Mean reward: -3.425
Mean number of steps: 9
Mean time taken to improve policy: 18026.9ms
Mean time to replenish particles: 0.008ms
Mean time taken: 25266.3ms
