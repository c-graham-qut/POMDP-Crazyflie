Seed: 1585325620
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.1
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
50635 histories in 2000.01ms.
Total solving time: 2000.04ms
Saving to file...    Done.
Global seed: 1585325626

Run #1
PRNG engine state: 805618634
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.1
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.1
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
51539 histories in 2000.02ms.
Before:                                 After:                                  
4.50808 from 50635 p. with 50635 starts.6.75636 from 102174 p. with 102174 starts.
Action children:                        Action children:                        
   +6.75:           FORWARD   39878        +8.00:           FORWARD   91417     
   -3.64:         REARRANGE    6480        -3.64:         REARRANGE    6480     
   -3.85:          NARROWER    2748        -3.85:          NARROWER    2748     
   -4.15:             WIDER    1208        -4.15:             WIDER    1208     
   -5.00:              LAND     321        -5.00:              LAND     321     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.125
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


Final State:
(7, 3) (7, 9) isLanded: 0
Belief #1
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
Total discounted reward: -0.125
# of steps: 1
Time spent on changes: 0ms
Time spent on policy updates: 2000.05ms
Time spent replenishing particles: 0.003ms
Time spent pruning: 0ms
Total time taken: 2004.2ms
Run complete!

Final State: (7, 3) (7, 9) isLanded: 0
Run #2
PRNG engine state: 805618634
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.1
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.1
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
51481 histories in 2000.02ms.
Before:                                 After:                                  
4.50808 from 50635 p. with 50635 starts.6.7551 from 102116 p. with 102116 starts.
Action children:                        Action children:                        
   +6.75:           FORWARD   39878        +8.00:           FORWARD   91359     
   -3.64:         REARRANGE    6480        -3.64:         REARRANGE    6480     
   -3.85:          NARROWER    2748        -3.85:          NARROWER    2748     
   -4.15:             WIDER    1208        -4.15:             WIDER    1208     
   -5.00:              LAND     321        -5.00:              LAND     321     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.125
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


Final State:
(7, 3) (7, 9) isLanded: 0
Belief #1
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
Total discounted reward: -0.125
# of steps: 1
Time spent on changes: 0ms
Time spent on policy updates: 2000.05ms
Time spent replenishing particles: 0.001ms
Time spent pruning: 0ms
Total time taken: 2004.28ms
Run complete!

Final State: (7, 3) (7, 9) isLanded: 0
Run #3
PRNG engine state: 805618634
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.1
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.1
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
50365 histories in 2000.01ms.
Before:                                 After:                                  
4.50808 from 50635 p. with 50635 starts.6.7306 from 101000 p. with 101000 starts.
Action children:                        Action children:                        
   +6.75:           FORWARD   39878        +7.99:           FORWARD   90243     
   -3.64:         REARRANGE    6480        -3.64:         REARRANGE    6480     
   -3.85:          NARROWER    2748        -3.85:          NARROWER    2748     
   -4.15:             WIDER    1208        -4.15:             WIDER    1208     
   -5.00:              LAND     321        -5.00:              LAND     321     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.125
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


Final State:
(7, 3) (7, 9) isLanded: 0
Belief #1
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
Total discounted reward: -0.125
# of steps: 1
Time spent on changes: 0ms
Time spent on policy updates: 2000.04ms
Time spent replenishing particles: 0.001ms
Time spent pruning: 0ms
Total time taken: 2004.23ms
Run complete!

Final State: (7, 3) (7, 9) isLanded: 0
