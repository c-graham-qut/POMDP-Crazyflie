Seed: 1586598779
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
55024 histories in 2000.02ms.
Total solving time: 2000.05ms
Saving to file...    Done.
Global seed: 1586598786

Run #1
PRNG engine state: 2109991663
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
51779 histories in 2000.01ms.
Before:                                 After:                                  
2.39324 from 55024 p. with 55024 starts.5.1954 from 106803 p. with 106803 starts.
Action children:                        Action children:                        
   +5.28:           FORWARD   38788        +6.93:           FORWARD   90567     
   -4.38:         REARRANGE    8959        -4.38:         REARRANGE    8959     
   -4.52:          NARROWER    4605        -4.52:          NARROWER    4605     
   -4.85:             WIDER    1559        -4.85:             WIDER    1559     
   -5.00:              LAND    1113        -5.00:              LAND    1113     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


t-1
State: (7, 3) (7, 9) isLanded: 0
Heuristic Value: 0
Belief #4
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
55131 histories in 2000.01ms.
Before:                                 After:                                  
7.15997 from 90567 p. with 0 starts.    7.63287 from 145698 p. with 55131 starts.
Action children:                        Action children:                        
   +7.95:           FORWARD   84689        +8.13:           FORWARD  139820     
   -4.05:         REARRANGE    2823        -4.05:         REARRANGE    2823     
   -4.17:          NARROWER    1941        -4.17:          NARROWER    1941     
   -4.60:             WIDER     720        -4.60:             WIDER     720     
   -5.00:              LAND     393        -5.00:              LAND     393     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (6, 3) (6, 9) isLanded = 0
Discount: 1; Total Reward: -0.225


t-2
State: (6, 3) (6, 9) isLanded: 0
Heuristic Value: 0
Belief #8
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 137057 of 161934 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 440.729 ms used for changes.
56204 histories in 2000.02ms.
Before:                                 After:                                  
8.35606 from 139820 p. with 0 starts.   5.0446 from 196024 p. with 56204 starts.
Action children:                        Action children:                        
   +8.53:           FORWARD  137835        +5.14:           FORWARD  194039     
   -3.62:         REARRANGE     905        -3.62:         REARRANGE     905     
   -3.83:          NARROWER     614        -3.83:          NARROWER     614     
   -4.27:             WIDER     316        -4.27:             WIDER     316     
   -5.00:              LAND     149        -5.00:              LAND     149     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (5, 3) (5, 9) isLanded = 0
Discount: 1; Total Reward: -0.45


t-3
State: (5, 3) (5, 9) isLanded: 0
Heuristic Value: 0
Belief #52
.............
...X.........
.............
.............
.............
...1.....2...
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 193240 of 218138 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 653.837 ms used for changes.
61945 histories in 2000.03ms.
Before:                                 After:                                  
5.36101 from 194039 p. with 0 starts.   5.54592 from 255984 p. with 61945 starts.
Action children:                        Action children:                        
   +5.39:           FORWARD  193448        +5.57:           FORWARD  255393     
   -3.22:         REARRANGE     223        -3.22:         REARRANGE     223     
   -3.37:          NARROWER     192        -3.37:          NARROWER     192     
   -3.87:             WIDER     120        -3.87:             WIDER     120     
   -5.00:              LAND      55        -5.00:              LAND      55     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (4, 3) (4, 9) isLanded = 0
Discount: 1; Total Reward: -0.675


t-4
State: (4, 3) (4, 9) isLanded: 0
Heuristic Value: 0
Belief #154
.............
...X.........
.............
.............
...1.....2...
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 255276 of 280083 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 996.215 ms used for changes.
75433 histories in 2000.01ms.
Before:                                 After:                                  
5.79199 from 255393 p. with 0 starts.   3.89405 from 330826 p. with 75433 starts.
Action children:                        Action children:                        
   +5.80:           FORWARD  255210        +3.90:           FORWARD  330643     
   -2.52:         REARRANGE      68        -2.52:         REARRANGE      68     
   -2.98:          NARROWER      50        -2.98:          NARROWER      50     
   -3.18:             WIDER      44        -3.18:             WIDER      44     
   -5.00:              LAND      20        -5.00:              LAND      20     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (3, 3) (3, 9) isLanded = 0
Discount: 1; Total Reward: -0.9


t-5
State: (3, 3) (3, 9) isLanded: 0
Heuristic Value: 0
Belief #1006
.............
...X.........
...X.........
...1.....2...
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 330570 of 355516 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1170.34 ms used for changes.
97860 histories in 2000.02ms.
Before:                                 After:                                  
4.1229 from 330643 p. with 0 starts.    2.65383 from 428503 p. with 97860 starts.
Action children:                        Action children:                        
   +4.13:           FORWARD  330547        +2.66:           FORWARD  428376     
   -2.63:             WIDER      28        -3.47:          NARROWER      35     
   -2.83:         REARRANGE      26        -3.56:         REARRANGE      34     
   -3.17:          NARROWER      25        -3.75:             WIDER      35     
   -5.00:              LAND      16        -5.00:              LAND      22     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -11.225
Observation: (2, 3) (2, 9) isLanded = 0
Discount: 1; Total Reward: -1.125


t-6
State: (2, 3) (2, 9) isLanded: 0
Heuristic Value: 0
Belief #1826
.............
...X.........
...@.....2...
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 428376 of 453376 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1510.4 ms used for changes.
111295 histories in 2000.02ms.
Before:                                 After:                                  
7.32925 from 428376 p. with 0 starts.   7.65772 from 539671 p. with 111295 starts.
Action children:                        Action children:                        
   +8.91:          NARROWER  223145        +8.91:          NARROWER  334440     
   +5.62:           FORWARD  205180        +5.62:           FORWARD  205180     
   -2.17:         REARRANGE      21        -2.17:         REARRANGE      21     
   -2.85:             WIDER      18        -2.85:             WIDER      18     
   -5.00:              LAND      11        -5.00:              LAND      11     
                                                                                
Action: NARROWER
Transition: NULL
Reward: -0.225
Observation: (2, 4) (2, 8) isLanded = 0
Discount: 1; Total Reward: -12.35


t-7
State: (2, 4) (2, 8) isLanded: 0
Heuristic Value: 0
Belief #7747
.............
...X.........
...X1...2....
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 334440 of 564671 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1069.88 ms used for changes.
181684 histories in 2000.01ms.
Before:                                 After:                                  
9.13647 from 334440 p. with 0 starts.   9.1406 from 516124 p. with 181684 starts.
Action children:                        Action children:                        
   +9.14:           FORWARD  334404        +9.14:           FORWARD  516088     
   -2.89:         REARRANGE      11        -2.89:         REARRANGE      11     
   -3.95:          NARROWER       8        -3.95:          NARROWER       8     
   -4.99:             WIDER       9        -4.99:             WIDER       9     
   -5.00:              LAND       7        -5.00:              LAND       7     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.425
Observation: (1, 4) (1, 8) isLanded = 0
Discount: 1; Total Reward: -12.575


t-8
State: (1, 4) (1, 8) isLanded: 0
Heuristic Value: 0
Belief #15184
.............
...X1...2....
...X.........
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 516088 of 746355 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1144.99 ms used for changes.
302222 histories in 2007.4ms.
Before:                                 After:                                  
9.56652 from 516088 p. with 0 starts.   9.56917 from 818310 p. with 302222 starts.
Action children:                        Action children:                        
   +9.58:              LAND  509706        +9.58:              LAND  811130     
   +8.98:         REARRANGE    3184        +9.00:         REARRANGE    3631     
   +8.95:           FORWARD    2891        +8.96:           FORWARD    3209     
   +7.54:          NARROWER     302        +7.60:          NARROWER     335     
   -9.09:             WIDER       4        -9.09:             WIDER       4     
                                                                                
Reached a terminal state!
Action: LAND
Transition: NULL
Reward: 9.575
Observation: (1, 4) (1, 8) isLanded = 1
Discount: 1; Total Reward: -13


Final State:
(1, 4) (1, 8) isLanded: 1
Belief #16595
.............
...X1...2....
...X.........
.............
.............
.............
.............
.............
.............
.............
Total discounted reward: -3.425
# of steps: 9
Time spent on changes: 6986.31ms
Time spent on policy updates: 18007.9ms
Time spent replenishing particles: 0.012ms
Time spent pruning: 0ms
Total time taken: 25068.1ms
Run complete!

Final State: (1, 4) (1, 8) isLanded: 1
1 runs completed.
Mean reward: -3.425
Mean number of steps: 9
Mean time taken to improve policy: 18007.9ms
Mean time to replenish particles: 0.012ms
Mean time taken: 25068.1ms
