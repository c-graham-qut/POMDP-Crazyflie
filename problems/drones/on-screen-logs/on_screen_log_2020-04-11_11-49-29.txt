Seed: 1586598570
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
54206 histories in 2000.01ms.
Total solving time: 2000.05ms
Saving to file...    Done.
Global seed: 1586598576

Run #1
PRNG engine state: 1496867585
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
52403 histories in 2000.03ms.
Before:                                 After:                                  
3.46997 from 54206 p. with 54206 starts.5.78233 from 106609 p. with 106609 starts.
Action children:                        Action children:                        
   +5.96:           FORWARD   41229        +7.20:           FORWARD   93632     
   -4.30:         REARRANGE    7205        -4.30:         REARRANGE    7205     
   -4.46:          NARROWER    3527        -4.46:          NARROWER    3527     
   -4.77:             WIDER    1385        -4.77:             WIDER    1385     
   -5.00:              LAND     860        -5.00:              LAND     860     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


t-1
State: (7, 3) (7, 9) isLanded: 0
Heuristic Value: 0
Belief #5
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
54356 histories in 2000.03ms.
Before:                                 After:                                  
7.42392 from 93632 p. with 0 starts.    7.78626 from 147988 p. with 54356 starts.
Action children:                        Action children:                        
   +8.03:           FORWARD   88957        +8.18:           FORWARD  143313     
   -3.93:         REARRANGE    2481        -3.93:         REARRANGE    2481     
   -4.16:          NARROWER    1306        -4.16:          NARROWER    1306     
   -4.58:             WIDER     568        -4.58:             WIDER     568     
   -5.00:              LAND     319        -5.00:              LAND     319     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (6, 3) (6, 9) isLanded = 0
Discount: 1; Total Reward: -0.225


t-2
State: (6, 3) (6, 9) isLanded: 0
Heuristic Value: 0
Belief #22
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 140974 of 160965 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 408.233 ms used for changes.
60930 histories in 2000.03ms.
Before:                                 After:                                  
8.40048 from 143313 p. with 0 starts.   4.95166 from 204243 p. with 60930 starts.
Action children:                        Action children:                        
   +8.54:           FORWARD  141667        +5.02:           FORWARD  202597     
   -3.51:         REARRANGE     763        -3.51:         REARRANGE     763     
   -3.73:          NARROWER     517        -3.73:          NARROWER     517     
   -4.31:             WIDER     240        -4.31:             WIDER     240     
   -5.00:              LAND     125        -5.00:              LAND     125     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (5, 3) (5, 9) isLanded = 0
Discount: 1; Total Reward: -0.45


t-3
State: (5, 3) (5, 9) isLanded: 0
Heuristic Value: 0
Belief #34
.............
...X.........
.............
.............
.............
...1.....2...
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 201888 of 221895 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 636.271 ms used for changes.
61919 histories in 2000.02ms.
Before:                                 After:                                  
5.24783 from 202597 p. with 0 starts.   4.90122 from 264516 p. with 61919 starts.
Action children:                        Action children:                        
   +5.27:           FORWARD  202073        +4.92:           FORWARD  263992     
   -3.06:         REARRANGE     205        -3.06:         REARRANGE     205     
   -3.24:          NARROWER     171        -3.24:          NARROWER     171     
   -3.88:             WIDER      99        -3.88:             WIDER      99     
   -5.00:              LAND      48        -5.00:              LAND      48     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (4, 3) (4, 9) isLanded = 0
Discount: 1; Total Reward: -0.675


t-4
State: (4, 3) (4, 9) isLanded: 0
Heuristic Value: 0
Belief #235
.............
...X.........
.............
.............
...1.....2...
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 264117 of 283814 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1036.11 ms used for changes.
83495 histories in 2000.01ms.
Before:                                 After:                                  
5.14279 from 263992 p. with 0 starts.   3.10628 from 347487 p. with 83495 starts.
Action children:                        Action children:                        
   +5.15:           FORWARD  263822        +3.11:           FORWARD  347315     
   -2.40:         REARRANGE      60        -2.40:         REARRANGE      60     
   -2.83:          NARROWER      47        -2.83:          NARROWER      47     
   -2.96:             WIDER      44        -2.96:             WIDER      44     
   -5.00:              LAND      18        -5.00:              LAND      20     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (3, 3) (3, 9) isLanded = 0
Discount: 1; Total Reward: -0.9


t-5
State: (3, 3) (3, 9) isLanded: 0
Heuristic Value: 0
Belief #657
.............
...X.........
...X.........
...1.....2...
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 347264 of 367309 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1214 ms used for changes.
98840 histories in 2000.01ms.
Before:                                 After:                                  
3.33428 from 347315 p. with 0 starts.   1.90812 from 446155 p. with 98840 starts.
Action children:                        Action children:                        
   +3.34:           FORWARD  347196        +1.91:           FORWARD  445995     
   -2.94:             WIDER      32        -3.18:          NARROWER      51     
   -2.97:          NARROWER      35        -3.86:         REARRANGE      42     
   -3.24:         REARRANGE      32        -4.30:             WIDER      39     
   -5.00:              LAND      19        -5.00:              LAND      27     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -11.225
Observation: (2, 3) (2, 9) isLanded = 0
Discount: 1; Total Reward: -1.125


t-6
State: (2, 3) (2, 9) isLanded: 0
Heuristic Value: 0
Belief #1503
.............
...X.........
...@.....2...
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 446450 of 466149 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1948.41 ms used for changes.
114129 histories in 2000.02ms.
Before:                                 After:                                  
6.63032 from 445995 p. with 0 starts.   6.93453 from 560124 p. with 114129 starts.
Action children:                        Action children:                        
   +8.11:             WIDER  221298        +8.12:             WIDER  335427     
   +5.17:           FORWARD  224645        +5.17:           FORWARD  224645     
   -2.68:          NARROWER      20        -2.68:          NARROWER      20     
   -3.10:         REARRANGE      19        -3.10:         REARRANGE      19     
   -5.00:              LAND      12        -5.00:              LAND      12     
                                                                                
Action: WIDER
Transition: NULL
Reward: -0.225
Observation: (2, 2) (2, 10) isLanded = 0
Discount: 1; Total Reward: -12.35


t-7
State: (2, 2) (2, 10) isLanded: 0
Heuristic Value: 0
Belief #8793
.............
...X.........
..1X......2..
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
ERROR: Impossible simulation history! Includes (2, 3) (2, 9) isLanded: 0


Final State:
(2, 2) (2, 10) isLanded: 0
Belief #8793
.............
...X.........
..1X......2..
.............
.............
.............
.............
.............
.............
.............
Total discounted reward: -12.575
# of steps: 7
Time spent on changes: 5243.02ms
Time spent on policy updates: 14000.4ms
Time spent replenishing particles: 0.007ms
Time spent pruning: 0ms
Total time taken: 19296.1ms
Run complete!

Final State: (2, 2) (2, 10) isLanded: 0
1 runs completed.
Mean reward: -12.575
Mean number of steps: 7
Mean time taken to improve policy: 14000.4ms
Mean time to replenish particles: 0.007ms
Mean time taken: 19296.1ms
