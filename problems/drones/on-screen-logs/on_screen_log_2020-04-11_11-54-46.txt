Seed: 1586598906
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
55211 histories in 2000.02ms.
Total solving time: 2000.07ms
Saving to file...    Done.
Global seed: 1586598912

Run #1
PRNG engine state: 1618872651
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
52433 histories in 2000.01ms.
Before:                                 After:                                  
2.52757 from 55211 p. with 55211 starts.5.27961 from 107644 p. with 107644 starts.
Action children:                        Action children:                        
   +5.34:           FORWARD   39414        +6.96:           FORWARD   91847     
   -4.37:         REARRANGE    8656        -4.37:         REARRANGE    8656     
   -4.50:          NARROWER    4521        -4.50:          NARROWER    4521     
   -4.83:             WIDER    1558        -4.83:             WIDER    1558     
   -5.00:              LAND    1062        -5.00:              LAND    1062     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


t-1
State: (7, 3) (7, 9) isLanded: 0
Heuristic Value: 0
Belief #3
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
56012 histories in 2000.02ms.
Before:                                 After:                                  
7.18534 from 91847 p. with 0 starts.    7.6507 from 147859 p. with 56012 starts.
Action children:                        Action children:                        
   +7.96:           FORWARD   86007        +8.14:           FORWARD  142019     
   -4.03:         REARRANGE    2792        -4.03:         REARRANGE    2792     
   -4.14:          NARROWER    1937        -4.14:          NARROWER    1937     
   -4.58:             WIDER     728        -4.58:             WIDER     728     
   -5.00:              LAND     382        -5.00:              LAND     382     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (6, 3) (6, 9) isLanded = 0
Discount: 1; Total Reward: -0.225


t-2
State: (6, 3) (6, 9) isLanded: 0
Heuristic Value: 0
Belief #10
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 139240 of 163656 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 405.392 ms used for changes.
61797 histories in 2000.01ms.
Before:                                 After:                                  
8.36291 from 142019 p. with 0 starts.   7.00289 from 203816 p. with 61797 starts.
Action children:                        Action children:                        
   +8.53:           FORWARD  140054        +7.11:           FORWARD  201851     
   -3.62:         REARRANGE     867        -3.62:         REARRANGE     867     
   -3.78:          NARROWER     642        -3.78:          NARROWER     642     
   -4.27:             WIDER     309        -4.27:             WIDER     309     
   -5.00:              LAND     146        -5.00:              LAND     146     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (5, 3) (5, 9) isLanded = 0
Discount: 1; Total Reward: -0.45


t-3
State: (5, 3) (5, 9) isLanded: 0
Heuristic Value: 0
Belief #70
.............
...X.........
.............
.............
.............
...1.....2...
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 201025 of 225453 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 639.178 ms used for changes.
60093 histories in 2000.03ms.
Before:                                 After:                                  
7.33381 from 201851 p. with 0 starts.   6.70122 from 261944 p. with 60093 starts.
Action children:                        Action children:                        
   +7.37:           FORWARD  201224        +6.73:           FORWARD  261317     
   -3.16:         REARRANGE     240        -3.16:         REARRANGE     240     
   -3.33:          NARROWER     198        -3.33:          NARROWER     198     
   -3.75:             WIDER     133        -3.75:             WIDER     133     
   -5.00:              LAND      55        -5.00:              LAND      55     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (4, 3) (4, 9) isLanded = 0
Discount: 1; Total Reward: -0.675


t-4
State: (4, 3) (4, 9) isLanded: 0
Heuristic Value: 0
Belief #297
.............
...X.........
.............
.............
...1.....2...
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 261190 of 285546 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 988.511 ms used for changes.
80775 histories in 2000.02ms.
Before:                                 After:                                  
6.9507 from 261317 p. with 0 starts.    5.50816 from 342092 p. with 80775 starts.
Action children:                        Action children:                        
   +6.96:           FORWARD  261130        +5.51:           FORWARD  341905     
   -2.41:         REARRANGE      71        -2.41:         REARRANGE      71     
   -2.90:          NARROWER      52        -2.90:          NARROWER      52     
   -3.21:             WIDER      43        -3.21:             WIDER      43     
   -5.00:              LAND      20        -5.00:              LAND      20     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (3, 3) (3, 9) isLanded = 0
Discount: 1; Total Reward: -0.9


t-5
State: (3, 3) (3, 9) isLanded: 0
Heuristic Value: 0
Belief #975
.............
...X.........
...X.........
...1.....2...
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 341850 of 366321 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1226.46 ms used for changes.
95402 histories in 2000.02ms.
Before:                                 After:                                  
5.73781 from 341905 p. with 0 starts.   4.72151 from 437307 p. with 95402 starts.
Action children:                        Action children:                        
   +5.74:           FORWARD  341834        +4.72:           FORWARD  437217     
   -2.03:          NARROWER      21        -2.22:         REARRANGE      27     
   -2.26:         REARRANGE      20        -2.40:          NARROWER      26     
   -2.76:             WIDER      18        -2.97:             WIDER      22     
   -5.00:              LAND      11        -5.00:              LAND      14     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -4.225
Observation: (2, 3) (2, 9) isLanded = 0
Discount: 1; Total Reward: -1.125


t-6
State: (2, 3) (2, 9) isLanded: 0
Heuristic Value: 0
Belief #1372
.............
...X.........
...@.....2...
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 437217 of 461723 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1249.18 ms used for changes.
114796 histories in 2000.02ms.
Before:                                 After:                                  
6.55955 from 437217 p. with 0 starts.   6.29999 from 552013 p. with 114796 starts.
Action children:                        Action children:                        
   +6.56:           FORWARD  437152        +6.30:           FORWARD  551945     
   -1.72:         REARRANGE      20        -2.05:         REARRANGE      21     
   -1.96:          NARROWER      18        -2.32:          NARROWER      19     
   -2.83:             WIDER      16        -2.83:             WIDER      16     
   -5.00:              LAND      10        -5.00:              LAND      11     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -4.225
Observation: (1, 3) (1, 9) isLanded = 0
Discount: 1; Total Reward: -5.35


t-7
State: (1, 3) (1, 9) isLanded: 0
Heuristic Value: 0
Belief #4131
.............
...@.....2...
...X.........
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 551945 of 576519 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1602.24 ms used for changes.
161769 histories in 2000.02ms.
Before:                                 After:                                  
9.51767 from 551945 p. with 0 starts.   9.52291 from 713714 p. with 161769 starts.
Action children:                        Action children:                        
   +9.54:           FORWARD  401134        +9.54:           FORWARD  561728     
   +9.50:              LAND  141171        +9.49:              LAND  141407     
   +9.11:          NARROWER    5633        +9.13:          NARROWER    6445     
   +8.86:         REARRANGE    2498        +8.85:         REARRANGE    2502     
   +8.66:             WIDER    1508        +8.68:             WIDER    1631     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (0, 3) (0, 9) isLanded = 0
Discount: 1; Total Reward: -9.575


t-8
State: (0, 3) (0, 9) isLanded: 0
Heuristic Value: 0
Belief #16080
...1.....2...
...X.........
...X.........
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 561728 of 738288 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1319.52 ms used for changes.
328444 histories in 2000.01ms.
Before:                                 After:                                  
9.76562 from 561728 p. with 0 starts.   9.76863 from 890172 p. with 328444 starts.
Action children:                        Action children:                        
   +9.78:              LAND  553159        +9.78:              LAND  880562     
   +9.31:         REARRANGE    5007        +9.34:         REARRANGE    5968     
   +9.09:          NARROWER    2489        +9.08:          NARROWER    2567     
   +8.70:             WIDER    1066        +8.68:             WIDER    1068     
   -6.16:           FORWARD       6        -6.16:           FORWARD       6     
                                                                                
Reached a terminal state!
Action: LAND
Transition: NULL
Reward: 9.775
Observation: (0, 3) (0, 9) isLanded = 1
Discount: 1; Total Reward: -9.8


Final State:
(0, 3) (0, 9) isLanded: 1
Belief #16086
...1.....2...
...X.........
...X.........
.............
.............
.............
.............
.............
.............
.............
Total discounted reward: -0.025
# of steps: 9
Time spent on changes: 7430.41ms
Time spent on policy updates: 18000.5ms
Time spent replenishing particles: 0.009ms
Time spent pruning: 0ms
Total time taken: 25513.5ms
Run complete!

Final State: (0, 3) (0, 9) isLanded: 1
1 runs completed.
Mean reward: -0.025
Mean number of steps: 9
Mean time taken to improve policy: 18000.5ms
Mean time to replenish particles: 0.009ms
Mean time taken: 25513.5ms
