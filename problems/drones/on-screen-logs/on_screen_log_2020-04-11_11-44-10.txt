Seed: 1586598250
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
54964 histories in 2000.01ms.
Total solving time: 2000.04ms
Saving to file...    Done.
Global seed: 1586598256

Run #1
PRNG engine state: 1278411158
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
51060 histories in 2000.03ms.
Before:                                 After:                                  
1.4614 from 54964 p. with 54964 starts. 4.6908 from 106024 p. with 106024 starts.
Action children:                        Action children:                        
   +4.51:           FORWARD   36478        +6.64:           FORWARD   87538     
   -4.44:         REARRANGE    9982        -4.44:         REARRANGE    9982     
   -4.56:          NARROWER    5421        -4.56:          NARROWER    5421     
   -4.89:             WIDER    1744        -4.89:             WIDER    1744     
   -5.00:              LAND    1339        -5.00:              LAND    1339     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


t-1
State: (7, 3) (7, 9) isLanded: 0
Heuristic Value: 0
Belief #3
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
55829 histories in 2000.02ms.
Before:                                 After:                                  
6.8697 from 87538 p. with 0 starts.     7.46883 from 143367 p. with 55829 starts.
Action children:                        Action children:                        
   +7.84:           FORWARD   80525        +8.07:           FORWARD  136354     
   -4.09:         REARRANGE    3582        -4.09:         REARRANGE    3582     
   -4.24:          NARROWER    2154        -4.24:          NARROWER    2154     
   -4.65:             WIDER     814        -4.65:             WIDER     814     
   -5.00:              LAND     462        -5.00:              LAND     462     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (6, 3) (6, 9) isLanded = 0
Discount: 1; Total Reward: -0.225


t-2
State: (6, 3) (6, 9) isLanded: 0
Heuristic Value: 0
Belief #8
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 133077 of 161853 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 389.426 ms used for changes.
59825 histories in 2000.01ms.
Before:                                 After:                                  
8.29725 from 136354 p. with 0 starts.   4.80589 from 196179 p. with 59825 starts.
Action children:                        Action children:                        
   +8.51:           FORWARD  134046        +4.91:           FORWARD  193871     
   -3.71:         REARRANGE    1057        -3.71:         REARRANGE    1057     
   -3.91:          NARROWER     700        -3.91:          NARROWER     700     
   -4.30:             WIDER     377        -4.30:             WIDER     377     
   -5.00:              LAND     173        -5.00:              LAND     173     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (5, 3) (5, 9) isLanded = 0
Discount: 1; Total Reward: -0.45


t-3
State: (5, 3) (5, 9) isLanded: 0
Heuristic Value: 0
Belief #38
.............
...X.........
.............
.............
.............
...1.....2...
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 192882 of 221678 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 623.144 ms used for changes.
63372 histories in 2011.75ms.
Before:                                 After:                                  
5.13526 from 193871 p. with 0 starts.   3.715 from 257243 p. with 63372 starts. 
Action children:                        Action children:                        
   +5.17:           FORWARD  193129        +3.74:           FORWARD  256501     
   -3.21:         REARRANGE     314        -3.21:         REARRANGE     314     
   -3.50:          NARROWER     220        -3.50:          NARROWER     220     
   -3.94:             WIDER     142        -3.94:             WIDER     142     
   -5.00:              LAND      65        -5.00:              LAND      65     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (4, 3) (4, 9) isLanded = 0
Discount: 1; Total Reward: -0.675


t-4
State: (4, 3) (4, 9) isLanded: 0
Heuristic Value: 0
Belief #219
.............
...X.........
.............
.............
...1.....2...
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 256357 of 285050 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 985.455 ms used for changes.
78123 histories in 2000.03ms.
Before:                                 After:                                  
3.96112 from 256501 p. with 0 starts.   2.44209 from 334624 p. with 78123 starts.
Action children:                        Action children:                        
   +3.97:           FORWARD  256279        +2.45:           FORWARD  334402     
   -2.60:         REARRANGE      85        -2.60:         REARRANGE      85     
   -2.91:          NARROWER      68        -2.91:          NARROWER      68     
   -3.60:             WIDER      45        -3.60:             WIDER      45     
   -5.00:              LAND      23        -5.00:              LAND      23     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (3, 3) (3, 9) isLanded = 0
Discount: 1; Total Reward: -0.9


t-5
State: (3, 3) (3, 9) isLanded: 0
Heuristic Value: 0
Belief #829
.............
...X.........
...X.........
...1.....2...
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 334303 of 363173 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1217.71 ms used for changes.
96349 histories in 2000.02ms.
Before:                                 After:                                  
2.6708 from 334402 p. with 0 starts.    1.5579 from 430751 p. with 96349 starts.
Action children:                        Action children:                        
   +2.67:           FORWARD  334263        +1.56:           FORWARD  430580     
   -3.02:         REARRANGE      39        -3.31:         REARRANGE      54     
   -3.20:          NARROWER      42        -3.64:          NARROWER      48     
   -3.83:             WIDER      35        -4.50:             WIDER      38     
   -5.00:              LAND      22        -5.00:              LAND      30     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -11.225
Observation: (2, 3) (2, 9) isLanded = 0
Discount: 1; Total Reward: -1.125


t-6
State: (2, 3) (2, 9) isLanded: 0
Heuristic Value: 0
Belief #2389
.............
...X.........
...@.....2...
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 430580 of 459522 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1488.44 ms used for changes.
111744 histories in 2000.01ms.
Before:                                 After:                                  
6.24076 from 430580 p. with 0 starts.   6.79317 from 542324 p. with 111744 starts.
Action children:                        Action children:                        
   +8.91:          NARROWER  185118        +8.91:          NARROWER  296862     
   +4.23:           FORWARD  245399        +4.23:           FORWARD  245399     
   -3.08:             WIDER      26        -3.08:             WIDER      26     
   -3.62:         REARRANGE      21        -3.62:         REARRANGE      21     
   -5.00:              LAND      15        -5.00:              LAND      15     
                                                                                
Action: NARROWER
Transition: NULL
Reward: -0.225
Observation: (2, 4) (2, 8) isLanded = 0
Discount: 1; Total Reward: -12.35


t-7
State: (2, 4) (2, 8) isLanded: 0
Heuristic Value: 0
Belief #7481
.............
...X.........
...X1...2....
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 296862 of 571266 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 993.259 ms used for changes.
187510 histories in 2000.01ms.
Before:                                 After:                                  
9.13689 from 296862 p. with 0 starts.   9.14148 from 484372 p. with 187510 starts.
Action children:                        Action children:                        
   +9.14:           FORWARD  296829        +9.14:           FORWARD  484339     
   -2.62:         REARRANGE      10        -2.62:         REARRANGE      10     
   -3.95:          NARROWER       8        -3.95:          NARROWER       8     
   -4.56:             WIDER       7        -4.56:             WIDER       7     
   -5.00:              LAND       7        -5.00:              LAND       7     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.425
Observation: (1, 4) (1, 8) isLanded = 0
Discount: 1; Total Reward: -12.575


t-8
State: (1, 4) (1, 8) isLanded: 0
Heuristic Value: 0
Belief #18648
.............
...X1...2....
...X.........
.............
.............
.............
.............
.............
.............
.............
292409 histories in 2000.01ms.
Before:                                 After:                                  
9.56737 from 484339 p. with 0 starts.   9.56926 from 776748 p. with 292409 starts.
Action children:                        Action children:                        
   +9.58:              LAND  479007        +9.58:              LAND  770568     
   +8.97:           FORWARD    3029        +8.98:           FORWARD    3330     
   +8.86:         REARRANGE    2281        +8.88:         REARRANGE    2516     
   +1.01:          NARROWER      18        +7.59:          NARROWER     330     
  -15.24:             WIDER       3       -15.24:             WIDER       3     
                                                                                
Reached a terminal state!
Action: LAND
Transition: NULL
Reward: 9.575
Observation: (1, 4) (1, 8) isLanded = 1
Discount: 1; Total Reward: -13


Final State:
(1, 4) (1, 8) isLanded: 1
Belief #18801
.............
...X1...2....
...X.........
.............
.............
.............
.............
.............
.............
.............
Total discounted reward: -3.425
# of steps: 9
Time spent on changes: 5697.38ms
Time spent on policy updates: 18012.2ms
Time spent replenishing particles: 0.009ms
Time spent pruning: 0ms
Total time taken: 23780.8ms
Run complete!

Final State: (1, 4) (1, 8) isLanded: 1
1 runs completed.
Mean reward: -3.425
Mean number of steps: 9
Mean time taken to improve policy: 18012.2ms
Mean time to replenish particles: 0.009ms
Mean time taken: 23780.8ms
