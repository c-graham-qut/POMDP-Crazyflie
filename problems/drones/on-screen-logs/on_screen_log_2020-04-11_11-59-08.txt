Seed: 1586599167
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
50182 histories in 2000.02ms.
Total solving time: 2000.06ms
Saving to file...    Done.
Global seed: 1586599174

Run #1
PRNG engine state: 1381658894
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
50176 histories in 2000.03ms.
Before:                                 After:                                  
8.1983 from 50182 p. with 50182 starts. 8.19927 from 100358 p. with 100358 starts.
Action children:                        Action children:                        
   +8.20:           FORWARD   41382        +8.20:           FORWARD   91558     
   -1.53:         REARRANGE    4906        -1.53:         REARRANGE    4906     
   -1.69:          NARROWER    2654        -1.69:          NARROWER    2654     
   -2.01:             WIDER    1177        -2.01:             WIDER    1177     
   -5.00:              LAND      63        -5.00:              LAND      63     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


t-1
State: (7, 3) (7, 9) isLanded: 0
Heuristic Value: 0
Belief #1
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
54971 histories in 2000.01ms.
Before:                                 After:                                  
8.42436 from 91558 p. with 0 starts.    8.42461 from 146529 p. with 54971 starts.
Action children:                        Action children:                        
   +8.42:           FORWARD   88282        +8.42:           FORWARD  143253     
   -1.30:         REARRANGE    1631        -1.30:         REARRANGE    1631     
   -1.48:          NARROWER    1055        -1.48:          NARROWER    1055     
   -1.83:             WIDER     545        -1.83:             WIDER     545     
   -5.00:              LAND      44        -5.00:              LAND      44     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (6, 3) (6, 9) isLanded = 0
Discount: 1; Total Reward: -0.225


t-2
State: (6, 3) (6, 9) isLanded: 0
Heuristic Value: 0
Belief #10
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 141637 of 155329 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 454.924 ms used for changes.
57778 histories in 2000.01ms.
Before:                                 After:                                  
8.64967 from 143253 p. with 0 starts.   7.22278 from 201031 p. with 57778 starts.
Action children:                        Action children:                        
   +8.65:           FORWARD  142119        +7.22:           FORWARD  199897     
   -1.08:         REARRANGE     497        -1.08:         REARRANGE     497     
   -1.27:          NARROWER     374        -1.27:          NARROWER     374     
   -1.64:             WIDER     234        -1.64:             WIDER     234     
   -5.00:              LAND      28        -5.00:              LAND      28     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (5, 3) (5, 9) isLanded = 0
Discount: 1; Total Reward: -0.45


t-3
State: (5, 3) (5, 9) isLanded: 0
Heuristic Value: 0
Belief #70
.............
...X.........
.............
.............
.............
...1.....2...
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 199381 of 213107 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 687.52 ms used for changes.
60955 histories in 2000.01ms.
Before:                                 After:                                  
7.44782 from 199897 p. with 0 starts.   7.44966 from 260852 p. with 60955 starts.
Action children:                        Action children:                        
   +7.45:           FORWARD  199539        +7.45:           FORWARD  260494     
   -0.86:         REARRANGE     138        -0.86:         REARRANGE     138     
   -1.05:          NARROWER     117        -1.05:          NARROWER     117     
   -1.43:             WIDER      86        -1.43:             WIDER      86     
   -5.00:              LAND      16        -5.00:              LAND      16     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (4, 3) (4, 9) isLanded = 0
Discount: 1; Total Reward: -0.675


t-4
State: (4, 3) (4, 9) isLanded: 0
Heuristic Value: 0
Belief #260
.............
...X.........
.............
.............
...1.....2...
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 260421 of 274062 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1062.1 ms used for changes.
80751 histories in 2000.01ms.
Before:                                 After:                                  
7.67469 from 260494 p. with 0 starts.   5.07157 from 341245 p. with 80751 starts.
Action children:                        Action children:                        
   +7.67:           FORWARD  260389        +5.07:           FORWARD  341124     
   -0.63:         REARRANGE      35        -0.64:         REARRANGE      39     
   -0.83:          NARROWER      32        -0.83:          NARROWER      36     
   -1.20:             WIDER      27        -1.21:             WIDER      32     
   -5.00:              LAND      10        -5.00:              LAND      13     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (3, 3) (3, 9) isLanded = 0
Discount: 1; Total Reward: -0.9


t-5
State: (3, 3) (3, 9) isLanded: 0
Heuristic Value: 0
Belief #425
.............
...X.........
...X.........
...1.....2...
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 341043 of 354813 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1253.71 ms used for changes.
100614 histories in 2016.1ms.
Before:                                 After:                                  
5.29659 from 341124 p. with 0 starts.   3.38493 from 441738 p. with 100614 starts.
Action children:                        Action children:                        
   +5.30:           FORWARD  341011        +3.38:           FORWARD  441537     
   -0.64:         REARRANGE      36        -1.00:         REARRANGE      66     
   -0.83:          NARROWER      34        -1.02:          NARROWER      66     
   -1.21:             WIDER      30        -1.73:             WIDER      49     
   -5.00:              LAND      12        -5.00:              LAND      19     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -11.225
Observation: (2, 3) (2, 9) isLanded = 0
Discount: 1; Total Reward: -1.125


t-6
State: (2, 3) (2, 9) isLanded: 0
Heuristic Value: 0
Belief #2205
.............
...X.........
...@.....2...
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 441537 of 455427 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1578.28 ms used for changes.
116405 histories in 2000.02ms.
Before:                                 After:                                  
8.12493 from 441537 p. with 0 starts.   8.12495 from 557942 p. with 116405 starts.
Action children:                        Action children:                        
   +8.12:             WIDER  250689        +8.12:             WIDER  367094     
   +6.54:           FORWARD  190790        +6.54:           FORWARD  190790     
   -0.62:         REARRANGE      24        -0.62:         REARRANGE      24     
   -0.80:          NARROWER      23        -0.80:          NARROWER      23     
   -5.00:              LAND      10        -5.00:              LAND      10     
                                                                                
Action: WIDER
Transition: NULL
Reward: -0.225
Observation: (2, 2) (2, 10) isLanded = 0
Discount: 1; Total Reward: -12.35


t-7
State: (2, 2) (2, 10) isLanded: 0
Heuristic Value: 0
Belief #8676
.............
...X.........
..1X......2..
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 367094 of 571832 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1164.37 ms used for changes.
158482 histories in 2000.01ms.
Before:                                 After:                                  
8.34998 from 367094 p. with 0 starts.   8.34998 from 525576 p. with 158482 starts.
Action children:                        Action children:                        
   +8.35:           FORWARD  367050        +8.35:           FORWARD  525531     
   -1.96:         REARRANGE      12        -1.97:         REARRANGE      13     
   -2.02:          NARROWER      13        -2.02:          NARROWER      13     
   -3.20:             WIDER      10        -3.20:             WIDER      10     
   -5.00:              LAND       8        -5.00:              LAND       8     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.825
Observation: (1, 2) (1, 10) isLanded = 0
Discount: 1; Total Reward: -12.575


t-8
State: (1, 2) (1, 10) isLanded: 0
Heuristic Value: 0
Belief #9778
.............
..1X......2..
...X.........
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 525531 of 730314 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1196.89 ms used for changes.
329160 histories in 2000.02ms.
Before:                                 After:                                  
9.175 from 525531 p. with 0 starts.     9.175 from 854691 p. with 329160 starts.
Action children:                        Action children:                        
   +9.17:              LAND  521882        +9.17:              LAND  850820     
   +8.34:           FORWARD    1699        +8.34:           FORWARD    1804     
   +8.34:         REARRANGE    1699        +8.34:         REARRANGE    1804     
   +6.92:             WIDER     248        +6.92:             WIDER     260     
  -17.44:          NARROWER       2       -17.44:          NARROWER       2     
                                                                                
Reached a terminal state!
Action: LAND
Transition: NULL
Reward: 9.175
Observation: (1, 2) (1, 10) isLanded = 1
Discount: 1; Total Reward: -13.4


Final State:
(1, 2) (1, 10) isLanded: 1
Belief #13004
.............
..1X......2..
...X.........
.............
.............
.............
.............
.............
.............
.............
Total discounted reward: -4.225
# of steps: 9
Time spent on changes: 7397.73ms
Time spent on policy updates: 18016.6ms
Time spent replenishing particles: 0.008ms
Time spent pruning: 0ms
Total time taken: 25489.3ms
Run complete!

Final State: (1, 2) (1, 10) isLanded: 1
1 runs completed.
Mean reward: -4.225
Mean number of steps: 9
Mean time taken to improve policy: 18016.6ms
Mean time to replenish particles: 0.008ms
Mean time taken: 25489.3ms
