Seed: 1586599713
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
55182 histories in 2000.02ms.
Total solving time: 2000.05ms
Saving to file...    Done.
Global seed: 1586599720

Run #1
PRNG engine state: 2116788038
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Loading policy... 
InitialPositions = (8, 3) (8, 9) 
Constructed the DronesModel
Discount: 1
Size: 10 by 13
measurement_uncertainty: 0 %
longitudinal_movement_uncertainty: 0 %
lateral_movement_uncertainty: 0 %
stepCost: 0.2
maximumDepth: 20
nActions: 5
nStVars: 5
minParticleCount: 5000
Environment:

 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
 0  0  0  0  0  0  0  0  0  0  0  0  0 
Running...


t-0
State: (8, 3) (8, 9) isLanded: 0
Heuristic Value: 0
Belief #0
.............
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
51926 histories in 2000.04ms.
Before:                                 After:                                  
1.88492 from 55182 p. with 55182 starts.4.93375 from 107108 p. with 107108 starts.
Action children:                        Action children:                        
   +4.94:           FORWARD   37403        +6.82:           FORWARD   89329     
   -4.43:         REARRANGE    9183        -4.43:         REARRANGE    9183     
   -4.53:          NARROWER    5510        -4.53:          NARROWER    5510     
   -4.85:             WIDER    1821        -4.85:             WIDER    1821     
   -5.00:              LAND    1265        -5.00:              LAND    1265     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (7, 3) (7, 9) isLanded = 0
Discount: 1; Total Reward: 0


t-1
State: (7, 3) (7, 9) isLanded: 0
Heuristic Value: 0
Belief #5
.............
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
55805 histories in 2000.03ms.
Before:                                 After:                                  
7.04591 from 89329 p. with 0 starts.    7.57128 from 145134 p. with 55805 starts.
Action children:                        Action children:                        
   +7.92:           FORWARD   82893        +8.12:           FORWARD  138698     
   -4.08:         REARRANGE    3238        -4.08:         REARRANGE    3238     
   -4.22:          NARROWER    1991        -4.22:          NARROWER    1991     
   -4.64:             WIDER     773        -4.64:             WIDER     773     
   -5.00:              LAND     433        -5.00:              LAND     433     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (6, 3) (6, 9) isLanded = 0
Discount: 1; Total Reward: -0.225


t-2
State: (6, 3) (6, 9) isLanded: 0
Heuristic Value: 0
Belief #8
.............
.............
.............
.............
.............
.............
...1.....2...
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 135843 of 162913 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 386.761 ms used for changes.
61065 histories in 2000.02ms.
Before:                                 After:                                  
8.34493 from 138698 p. with 0 starts.   4.83208 from 199763 p. with 61065 starts.
Action children:                        Action children:                        
   +8.52:           FORWARD  136704        +4.92:           FORWARD  197769     
   -3.71:         REARRANGE     893        -3.71:         REARRANGE     893     
   -3.92:          NARROWER     596        -3.92:          NARROWER     596     
   -4.30:             WIDER     345        -4.30:             WIDER     345     
   -5.00:              LAND     159        -5.00:              LAND     159     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (5, 3) (5, 9) isLanded = 0
Discount: 1; Total Reward: -0.45


t-3
State: (5, 3) (5, 9) isLanded: 0
Heuristic Value: 0
Belief #43
.............
...X.........
.............
.............
.............
...1.....2...
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 196889 of 223978 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 621.643 ms used for changes.
62162 histories in 2000.03ms.
Before:                                 After:                                  
5.14586 from 197769 p. with 0 starts.   4.85796 from 259931 p. with 62162 starts.
Action children:                        Action children:                        
   +5.17:           FORWARD  197111        +4.88:           FORWARD  259273     
   -3.16:         REARRANGE     283        -3.16:         REARRANGE     283     
   -3.56:          NARROWER     178        -3.56:          NARROWER     178     
   -3.85:             WIDER     136        -3.85:             WIDER     136     
   -5.00:              LAND      60        -5.00:              LAND      60     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (4, 3) (4, 9) isLanded = 0
Discount: 1; Total Reward: -0.675


t-4
State: (4, 3) (4, 9) isLanded: 0
Heuristic Value: 0
Belief #283
.............
...X.........
.............
.............
...1.....2...
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 259141 of 286140 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1019.15 ms used for changes.
82808 histories in 2000.01ms.
Before:                                 After:                                  
5.10436 from 259273 p. with 0 starts.   3.06231 from 342081 p. with 82808 starts.
Action children:                        Action children:                        
   +5.11:           FORWARD  259083        +3.07:           FORWARD  341891     
   -2.82:         REARRANGE      64        -2.82:         REARRANGE      64     
   -2.84:          NARROWER      62        -2.84:          NARROWER      62     
   -3.52:             WIDER      42        -3.52:             WIDER      42     
   -5.00:              LAND      21        -5.00:              LAND      21     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.225
Observation: (3, 3) (3, 9) isLanded = 0
Discount: 1; Total Reward: -0.9


t-5
State: (3, 3) (3, 9) isLanded: 0
Heuristic Value: 0
Belief #980
.............
...X.........
...X.........
...1.....2...
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 341798 of 368948 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1188.14 ms used for changes.
98725 histories in 2000.02ms.
Before:                                 After:                                  
3.29079 from 341891 p. with 0 starts.   1.85804 from 440616 p. with 98725 starts.
Action children:                        Action children:                        
   +3.29:           FORWARD  341768        +1.86:           FORWARD  440461     
   -2.54:         REARRANGE      37        -3.33:         REARRANGE      49     
   -2.95:          NARROWER      33        -3.93:          NARROWER      39     
   -2.95:             WIDER      33        -4.21:             WIDER      38     
   -5.00:              LAND      19        -5.00:              LAND      28     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -11.225
Observation: (2, 3) (2, 9) isLanded = 0
Discount: 1; Total Reward: -1.125


t-6
State: (2, 3) (2, 9) isLanded: 0
Heuristic Value: 0
Belief #1597
.............
...X.........
...@.....2...
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (2, 3) to (2, 3)
Must revise 440461 of 467673 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1491.76 ms used for changes.
114342 histories in 2000.02ms.
Before:                                 After:                                  
6.61695 from 440461 p. with 0 starts.   6.92748 from 554803 p. with 114342 starts.
Action children:                        Action children:                        
   +8.11:             WIDER  221742        +8.12:             WIDER  336084     
   +5.10:           FORWARD  218660        +5.10:           FORWARD  218660     
   -2.21:          NARROWER      23        -2.21:          NARROWER      23     
   -3.18:         REARRANGE      23        -3.18:         REARRANGE      23     
   -5.00:              LAND      12        -5.00:              LAND      12     
                                                                                
Action: WIDER
Transition: NULL
Reward: -0.225
Observation: (2, 2) (2, 10) isLanded = 0
Discount: 1; Total Reward: -12.35


t-7
State: (2, 2) (2, 10) isLanded: 0
Heuristic Value: 0
Belief #3234
.............
...X.........
..1X......2..
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 336084 of 582015 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1058.77 ms used for changes.
184090 histories in 2043.16ms.
Before:                                 After:                                  
8.34159 from 336084 p. with 0 starts.   8.34398 from 520174 p. with 184090 starts.
Action children:                        Action children:                        
   +8.34:           FORWARD  336048        +8.34:           FORWARD  520137     
   -3.61:         REARRANGE       9        -3.49:         REARRANGE      10     
   -3.94:             WIDER       9        -3.94:             WIDER       9     
   -5.00:              LAND       8        -5.00:              LAND       8     
   -5.39:          NARROWER       9        -5.39:          NARROWER       9     
                                                                                
Action: FORWARD
Transition: NULL
Reward: -0.825
Observation: (1, 2) (1, 10) isLanded = 0
Discount: 1; Total Reward: -12.575


t-8
State: (1, 2) (1, 10) isLanded: 0
Heuristic Value: 0
Belief #17617
.............
..1X......2..
...X.........
.............
.............
.............
.............
.............
.............
.............
Model changing.
Add Obstacles from (1, 3) to (1, 3)
Must revise 520137 of 766105 histories!
Deleted 0 histories!
Revision complete. Backing up...
Using search on 0 histories!
Changes complete
Total of 1155.08 ms used for changes.
314759 histories in 2000.01ms.
Before:                                 After:                                  
9.16988 from 520137 p. with 0 starts.   9.17161 from 834896 p. with 314759 starts.
Action children:                        Action children:                        
   +9.17:              LAND  517872        +9.17:              LAND  832429     
   +8.13:           FORWARD    1102        +8.15:           FORWARD    1203     
   +8.13:         REARRANGE    1102        +8.15:         REARRANGE    1203     
   +4.21:             WIDER      56        +4.21:             WIDER      56     
  -12.24:          NARROWER       4       -12.24:          NARROWER       4     
                                                                                
Reached a terminal state!
Action: LAND
Transition: NULL
Reward: 9.175
Observation: (1, 2) (1, 10) isLanded = 1
Discount: 1; Total Reward: -13.4


Final State:
(1, 2) (1, 10) isLanded: 1
Belief #17761
.............
..1X......2..
...X.........
.............
.............
.............
.............
.............
.............
.............
Total discounted reward: -4.225
# of steps: 9
Time spent on changes: 6921.23ms
Time spent on policy updates: 18043.7ms
Time spent replenishing particles: 0.01ms
Time spent pruning: 0ms
Total time taken: 25039.1ms
Run complete!

Final State: (1, 2) (1, 10) isLanded: 1
1 runs completed.
Mean reward: -4.225
Mean number of steps: 9
Mean time taken to improve policy: 18043.7ms
Mean time to replenish particles: 0.01ms
Mean time taken: 25039.1ms
